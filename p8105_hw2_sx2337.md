p8105_hw2_sx2337
================
Shun Xie
2022-09-27

``` r
#load all the data
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
options(tibble.print_min = 5)
```

# Problem 1

NYC_Transit_Subway_Entrance_And_Exit_Data is the dataset that includes
all the NYC transit data. First, clean the data:

``` r
NYC_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
head(NYC_transit)
```

    ## # A tibble: 6 × 19
    ##   line  stati…¹ stati…² stati…³ route1 route2 route3 route4 route5 route6 route7
    ##   <chr> <chr>     <dbl>   <dbl> <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
    ## 1 4 Av… 25th St    40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 2 4 Av… 25th St    40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 3 4 Av… 36th St    40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 4 4 Av… 36th St    40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 5 4 Av… 36th St    40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 6 4 Av… 45th St    40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>   <NA>  
    ## # … with 8 more variables: route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entrance_type <chr>, entry <lgl>, vending <chr>, ada <lgl>,
    ## #   and abbreviated variable names ¹​station_name, ²​station_latitude,
    ## #   ³​station_longitude

The original data set contains 33 varibles, namely: Division, Line,
Station Name, Station Latitude, Station Longitude, Route1, Route2,
Route3, Route4, Route5, Route6, Route7, Route8, Route9, Route10,
Route11, Entrance Type, Entry, Exit Only, Vending, Staffing, Staff
Hours, ADA, ADA Notes, Free Crossover, North South Street, East West
Street, Corner, Entrance Latitude, Entrance Longitude, Station Location
and Entrance Location. Out of these variables, I selected the required
variables for line, station, name, station latitude / longitude, routes
served, entry, vending, entrance type, and ADA compliance.

For data cleaning, I first clean the names of data using janitor
package, then select the required variables and change the entry
variable from character to logical variables. The resulting data is
shown above. The data is not exactly very tidy because there are a total
of 11 route variables that could be merge using pivot_longer function.
Additionally, the variable names are not all characters. Some of the
variables are double.

Now here is the answer to 3 questions:

1.  How many distinct stations are there?

``` r
distinct_station = distinct(NYC_transit, NYC_transit$line,NYC_transit$station_name,.keep_all=TRUE)
num_distinct_station = nrow(distinct_station)
print(num_distinct_station)
```

    ## [1] 465

First I use distinct function to find distinct pair of station name and
line. Note when keep_all=TRUE, all the variables in the dataframe will
be kept but with only distinct pair of station name and line. Then I use
nrow function to return the total number of row. There are a total of
465 distinct stations.

2.  How many stations are ADA compliant?

``` r
num_ADA = filter(distinct_station,ada==TRUE) %>%
  length()
print(num_ADA)
```

    ## [1] 21

First I filter and left all the station that is ada compliant. Then I
use length function to return the number of values left. There are a
total of 21 station that is ada compliant.

3.  What proportion of station entrances / exits without vending allow
    entrance?

``` r
num_no_vending = filter(NYC_transit, vending=='NO') %>%
  nrow()
num_total = nrow(NYC_transit)
proportion_without_vending = num_no_vending/num_total
print(proportion_without_vending)
```

    ## [1] 0.09796574

First I filter all the station entrances/ exits without vending and get
the number by using nrow(). Then I get the total number of station
entrances/exits. The proportion is 0.098 (3d.p.)

Now reform the data first by tidy up the variable name of route into
characters.

``` r
NYC_transit_adpt = mutate(NYC_transit,across(route1:route11, as.character))
```

Then, first get the reform data so that route number and route name are
distinct variables.

``` r
reform_NYC_transit = 
pivot_longer(NYC_transit_adpt,
    route1:route11,
    names_to = "route_number", 
    values_to = "route_name",
    values_drop_na = TRUE)
reform_NYC_transit
```

    ## # A tibble: 4,270 × 10
    ##   line     station…¹ stati…² stati…³ entra…⁴ entry vending ada   route…⁵ route…⁶
    ##   <chr>    <chr>       <dbl>   <dbl> <chr>   <lgl> <chr>   <lgl> <chr>   <chr>  
    ## 1 4 Avenue 25th St      40.7   -74.0 Stair   TRUE  YES     FALSE route1  R      
    ## 2 4 Avenue 25th St      40.7   -74.0 Stair   TRUE  YES     FALSE route1  R      
    ## 3 4 Avenue 36th St      40.7   -74.0 Stair   TRUE  YES     FALSE route1  N      
    ## 4 4 Avenue 36th St      40.7   -74.0 Stair   TRUE  YES     FALSE route2  R      
    ## 5 4 Avenue 36th St      40.7   -74.0 Stair   TRUE  YES     FALSE route1  N      
    ## # … with 4,265 more rows, and abbreviated variable names ¹​station_name,
    ## #   ²​station_latitude, ³​station_longitude, ⁴​entrance_type, ⁵​route_number,
    ## #   ⁶​route_name

To answer the question of How many distinct stations serve the A train,
I need to first filter the stations that serve A train and then return
all the distinct stations by distinct function. Lastly, get the number
by nrow(). Also I print out all the combinations in distinct_station_A
dataframe.

``` r
distinct_station_A = filter(reform_NYC_transit,route_name=='A') %>%
  distinct( line,station_name,.keep_all=TRUE) 

print(nrow(distinct_station_A))
```

    ## [1] 60

``` r
distinct_station_A
```

    ## # A tibble: 60 × 10
    ##   line       stati…¹ stati…² stati…³ entra…⁴ entry vending ada   route…⁵ route…⁶
    ##   <chr>      <chr>     <dbl>   <dbl> <chr>   <lgl> <chr>   <lgl> <chr>   <chr>  
    ## 1 42nd St S… Times …    40.8   -74.0 Stair   TRUE  YES     FALSE route1  A      
    ## 2 8 Avenue   125th …    40.8   -74.0 Stair   TRUE  YES     FALSE route1  A      
    ## 3 8 Avenue   145th …    40.8   -73.9 Stair   TRUE  YES     FALSE route1  A      
    ## 4 8 Avenue   14th St    40.7   -74.0 Easeme… TRUE  YES     TRUE  route1  A      
    ## 5 8 Avenue   168th …    40.8   -73.9 Stair   TRUE  YES     TRUE  route1  A      
    ## # … with 55 more rows, and abbreviated variable names ¹​station_name,
    ## #   ²​station_latitude, ³​station_longitude, ⁴​entrance_type, ⁵​route_number,
    ## #   ⁶​route_name

There are 60 distinct stations serve the A train.

``` r
ADA_distinct_station_A = filter(distinct_station_A,ada=='TRUE')
ADA_distinct_station_A
```

    ## # A tibble: 17 × 10
    ##    line      stati…¹ stati…² stati…³ entra…⁴ entry vending ada   route…⁵ route…⁶
    ##    <chr>     <chr>     <dbl>   <dbl> <chr>   <lgl> <chr>   <lgl> <chr>   <chr>  
    ##  1 8 Avenue  14th St    40.7   -74.0 Easeme… TRUE  YES     TRUE  route1  A      
    ##  2 8 Avenue  168th …    40.8   -73.9 Stair   TRUE  YES     TRUE  route1  A      
    ##  3 8 Avenue  175th …    40.8   -73.9 Elevat… TRUE  YES     TRUE  route1  A      
    ##  4 8 Avenue  34th St    40.8   -74.0 Elevat… TRUE  YES     TRUE  route1  A      
    ##  5 8 Avenue  42nd St    40.8   -74.0 Easeme… TRUE  YES     TRUE  route1  A      
    ##  6 8 Avenue  59th St    40.8   -74.0 Easeme… TRUE  YES     TRUE  route1  A      
    ##  7 8 Avenue  Inwood…    40.9   -73.9 Elevat… TRUE  YES     TRUE  route1  A      
    ##  8 8 Avenue  West 4…    40.7   -74.0 Elevat… TRUE  YES     TRUE  route1  A      
    ##  9 8 Avenue  World …    40.7   -74.0 Stair   TRUE  YES     TRUE  route1  A      
    ## 10 Broadway  Times …    40.8   -74.0 Stair   TRUE  YES     TRUE  route1  A      
    ## 11 Broadway… 59th S…    40.8   -74.0 Stair   TRUE  YES     TRUE  route1  A      
    ## 12 Broadway… Times …    40.8   -74.0 Easeme… TRUE  YES     TRUE  route1  A      
    ## 13 Canarsie  8th Av     40.7   -74.0 Stair   TRUE  YES     TRUE  route1  A      
    ## 14 Franklin  Frankl…    40.7   -74.0 Door    TRUE  YES     TRUE  route1  A      
    ## 15 Fulton    Euclid…    40.7   -73.9 Elevat… TRUE  YES     TRUE  route1  A      
    ## 16 Fulton    Frankl…    40.7   -74.0 Stair   TRUE  YES     TRUE  route1  A      
    ## 17 Rockaway  Howard…    40.7   -73.8 Elevat… TRUE  YES     TRUE  route1  A      
    ## # … with abbreviated variable names ¹​station_name, ²​station_latitude,
    ## #   ³​station_longitude, ⁴​entrance_type, ⁵​route_number, ⁶​route_name

``` r
print(nrow(ADA_distinct_station_A))
```

    ## [1] 17

By filtering all ada compliant from the distinct stations serve the A
train and return the number by using nrow, there are 17 station are ADA
compliant. All stored in ADA_distinct_station_A dataframe

# Problem 2

First, load the data. The first line of the data is a logo, in which
need to skip it. Also exclude the last several columns by specifying the
columns that need to be included in the range argument in read_excel.
After clean the names, change the variable name of weight_tons to weight
and Volume_cubic_yards to volume. After that, ommit rows that does not
include dumpster-specific data using drop_na function. The last row
contains grand total will also be excluded by using filter function
filters all rows except for the last row. Lastly, round the number of
sports balls to the nearest integer and converts the result to an
integer variable.

``` r
Mr_trash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",skip = 1,sheet=1,range = cellranger::cell_cols("A:N"))  %>%
  janitor::clean_names() %>%
  select(dumpster=dumpster, weight = weight_tons,volume = volume_cubic_yards,everything())%>%
  drop_na(dumpster) %>%
  filter(row_number()!=n())%>%
  mutate(sports_balls = as.integer(sports_balls))
  
Mr_trash_wheel
```

    ## # A tibble: 453 × 14
    ##   dumpster weight volume month  year date                plast…¹ polys…² cigar…³
    ##   <chr>     <dbl>  <dbl> <chr> <dbl> <dttm>                <dbl>   <dbl>   <dbl>
    ## 1 1          4.31     18 May    2014 2014-05-16 00:00:00    1450    1820  126000
    ## 2 2          2.74     13 May    2014 2014-05-16 00:00:00    1120    1030   91000
    ## 3 3          3.45     15 May    2014 2014-05-16 00:00:00    2450    3100  105000
    ## 4 4          3.1      15 May    2014 2014-05-17 00:00:00    2380    2730  100000
    ## 5 5          4.06     18 May    2014 2014-05-17 00:00:00     980     870  120000
    ## # … with 448 more rows, 5 more variables: glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, and abbreviated variable names ¹​plastic_bottles,
    ## #   ²​polystyrene, ³​cigarette_butts

Now do the similar process to Professor Trash Wheel.

``` r
Prof_trash_wheel = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",skip = 1,sheet=2,range = cellranger::cell_cols("A:N"))  %>%
  janitor::clean_names() %>%
  select(dumpster=dumpster, weight = weight_tons,volume = volume_cubic_yards,everything())%>%
  drop_na(dumpster) %>%
  filter(row_number()!=n())%>%
  mutate(sports_balls = as.integer(sports_balls))
  
Prof_trash_wheel
```

    ## # A tibble: 70 × 14
    ##   dumpster weight volume month  year date                plast…¹ polys…² cigar…³
    ##      <dbl>  <dbl>  <dbl> <chr> <dbl> <dttm>                <dbl>   <dbl>   <dbl>
    ## 1        1   1.79     15 Janu…  2017 2017-01-02 00:00:00    1950    6080   19700
    ## 2        2   1.58     15 Janu…  2017 2017-01-30 00:00:00    9540   11230   17600
    ## 3        3   2.32     18 Febr…  2017 2017-02-26 00:00:00    8350    9210   12000
    ## 4        4   3.72     15 Febr…  2017 2017-02-26 00:00:00    8590    1030   13000
    ## 5        5   1.45     15 Febr…  2017 2017-02-28 00:00:00    7830    9950   16000
    ## # … with 65 more rows, 5 more variables: glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, and abbreviated variable names ¹​plastic_bottles,
    ## #   ²​polystyrene, ³​cigarette_butts

First, add two columns specifying the dataset is Mr or Prof. Then join
two dataframes vertically using rbind:

``` r
Mr_trash_wheel = mutate(Mr_trash_wheel, Mr_or_prof = 'Mr')
Prof_trash_wheel = mutate(Prof_trash_wheel, Mr_or_prof = 'Prof')
merged_df = rbind(Mr_trash_wheel,Prof_trash_wheel)
```

The data has a total of `523` number of time that trash is collected and
dumped into a dumpster after combining Mr_trash_wheel and
Prof_trash_wheel. The key variables are the weight of dumpster measuring
in tons and the average of each dumpster weights `3.0277629`. For the
data collected by Mr Trash wheel, the average weight is `3.2002208` tons
whereas Prof Trash wheel has an average of `1.9117143` tons. Another
important factor is the volume of dumpsters, measuring in cubic yards.
The average volume of each dumpster is `15.3021033`. For the data
collected by Mr Trash wheel, the average volume is `15.4128035` cubic
yards whereas Prof Trash wheel has an average of `14.5857143` cubic
yards.

The dataset also measures number of plastic bottles, cigarette butts,
glass bottles, grocery bags, chip bags and sports balls. The average of
the above variables is: `2411.206501`, `2.3142826\times 10^{4}`,
`21.0305927`, `1394.8680688`, `2575.2122371`, `10.1854685` respectively.

The total weight of trash collected by Professor Trash Wheel is `133.82`
tons. The total number of sports balls collected by Mr. Trash Wheel in
2020 is `856`

# Problem 3

1.  Read the dataset
2.  Clean the names.
3.  Separate the mon variable into variables year month and day.
4.  As instructed, these variables need to be in integers. Therefore,
    use mutate function to convert all values in the variables into
    integers.
5.  After that, convert month into month name using moth.abb function in
    r.
6.  Then, create a president variable containing a classification of
    ‘dem’ or ‘goz’. If prez_dem==1, the president is democratic,
    otherwise the president is republican and must have prez_dem==1.
    Therefore, I can use ifelse function to check if presidence is gop
    or dem.  
7.  Follows the last step, I remove the columns of prez_dem and prez_gop
    using select function.
8.  Also remove the day variable in the last step.

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(mon,c('year','month','day'),sep='-') %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  mutate(month = month.abb[month]) %>%
  mutate(president = ifelse(prez_dem==1,'dem','gop')) %>%
  select(-prez_dem,-prez_gop) %>%
  select(-day)
pols_month
```

    ## # A tibble: 822 × 9
    ##    year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1  1947 Jan        23      51     253      23      45     198 dem      
    ## 2  1947 Feb        23      51     253      23      45     198 dem      
    ## 3  1947 Mar        23      51     253      23      45     198 dem      
    ## 4  1947 Apr        23      51     253      23      45     198 dem      
    ## 5  1947 May        23      51     253      23      45     198 dem      
    ## # … with 817 more rows

Now move on to cleaning the data in snp.csv with similar procedure: 1.
Read the data 2. Clean variable name 3. Seperate date into month day
year 4. Get into integer values 5. If year is smaller than 22, it means
year is from 2000 to 2022, thus, add 2000 to the year value. If it is
bigger than 22, i.e. 50, it means it is year 1950. Hence add 1900 if
year is bigger than 22. Use ifelse function to do so 6. Get month into
month name 7. Get rid of column of day 8. Organize so that year and
month are leading columns

``` r
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(date,c('month','day','year'),sep='/') %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  mutate(year = ifelse(year<22,year+2000,year+1900))%>%
  mutate(month = month.abb[month]) %>%
  select(-day)%>%
  select(year, month, everything())
head(snp)
```

    ## # A tibble: 6 × 3
    ##    year month close
    ##   <dbl> <chr> <dbl>
    ## 1  2015 Jul   2080.
    ## 2  2015 Jun   2063.
    ## 3  2015 May   2107.
    ## 4  2015 Apr   2086.
    ## 5  2015 Mar   2068.
    ## 6  2015 Feb   2104.

For unemployment data: The unemployment data has months in seperate
columns with respect to years. It needs to be convert into long
format: 1. load the data 2. All the data name are in desired form but
need to convert Year to lower case year 3. Convert into long format

``` r
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv",show_col_types = FALSE) %>%
  select(year = Year, everything())%>%
  pivot_longer(Jan:Dec,names_to = "month", values_to = "unemployment")
```

Now join the snp into pols. So pols are the dataframe that need to
contain all the values. Then join unemployment into pols_snp, so
pols_snp contains all the values.

``` r
pols_snp = left_join(pols_month,snp,by = c("year", "month"))
pols_snp_unemployment = left_join(pols_snp,unemployment,by = c("year", "month"))
pols_snp_unemployment
```

    ## # A tibble: 822 × 11
    ##    year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##   <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1  1947 Jan        23      51     253      23      45     198 dem          NA
    ## 2  1947 Feb        23      51     253      23      45     198 dem          NA
    ## 3  1947 Mar        23      51     253      23      45     198 dem          NA
    ## 4  1947 Apr        23      51     253      23      45     198 dem          NA
    ## 5  1947 May        23      51     253      23      45     198 dem          NA
    ## # … with 817 more rows, and 1 more variable: unemployment <dbl>

Dataset pols_month contains all the information related to whether
president was republican or democratic. It also contains the number of
governors, senators and representatives in each party. The total
dimension is `822` with `9` variables after tidying data. The range of
year is from `1947` to `2015`.

snp, on the other hand, contains the closing values of stock market
index on the association date. The total dimension for snp is `787` and
there are only `3` variables after tidying data, including year and
month. The values of stock market index ranging from year `1950` to
`2015`.

Unemployment contains the unemployment rate with respect to different
months in different years, ranging from year `1948` to `2015`. There are
`816` number of data and `3` of variables including year and month.

Now the merged dataset includes all three datasets, namely pols_month,
snp and unemployment. The resulting data has the same dimension as
pols_month data but with a wider range of variables. It has a total of
`11` variables, namely year and month as the key and 6 measurement of
number of governors, senators and representatives with respect to each
party, 1 variable of president measuring whether the president from
democrative or republican, closing values of stock market index and
unemployment. Although with some missing value, the year is from `1947`
to `2015`.
