---
title: "p8105_hw2_sx2337"
author: "Shun Xie"
date: "2022-09-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#load all the data
library(tidyverse)
options(tibble.print_min = 5)
```


# Problem 1
NYC_Transit_Subway_Entrance_And_Exit_Data is the dataset that includes all the NYC transit data. First, clean the data:

```{r,warning=FALSE}
NYC_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
head(NYC_transit)
```

The original data set contains 33 varibles, namely: Division,	Line,	Station Name,	Station Latitude,	Station Longitude,	Route1,	Route2,	Route3,	Route4,	Route5,	Route6,	Route7,	Route8,	Route9,	Route10,	Route11,	Entrance Type,	Entry,	Exit Only,	Vending,	Staffing,	Staff Hours,	ADA,	ADA Notes,	Free Crossover,	North South Street,	East West Street,	Corner,	Entrance Latitude,	Entrance Longitude,	Station Location and	Entrance Location. Out of these variables, I selected the required variables for line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.

For data cleaning, I first clean the names of data using janitor package, then select the required variables and change the entry variable from character to logical variables. The resulting data is shown above. The data is not exactly very tidy because there are a total of 11 route variables that could be merge using pivot_longer function. Additionally, the variable names are not all characters. Some of the variables are double. 


Now here is the answer to 3 questions:

1. How many distinct stations are there?
```{r}
distinct_station = distinct(NYC_transit, NYC_transit$line,NYC_transit$station_name,.keep_all=TRUE)
num_distinct_station = nrow(distinct_station)
print(num_distinct_station)
```
First I use distinct function to find distinct pair of station name and line. Note when keep_all=TRUE, all the variables in the dataframe will be kept but with only distinct pair of station name and line. Then I use nrow function to return the total number of row. 
There are a total of 465 distinct stations.

2. How many stations are ADA compliant?
```{r}
num_ADA = filter(distinct_station,ada==TRUE) %>%
  length()
print(num_ADA)
```
First I filter and left all the station that is ada compliant. Then I use length function to return the number of values left. 
There are a total of 21 station that is ada compliant.

3. What proportion of station entrances / exits without vending allow entrance?
```{r}
num_no_vending = filter(NYC_transit, vending=='NO') %>%
  nrow()
num_total = nrow(NYC_transit)
proportion_without_vending = num_no_vending/num_total
print(proportion_without_vending)
```
First I filter all the station entrances/ exits without vending and get the number by using nrow(). Then I get the total number of station entrances/exits. 
The proportion is 0.098 (3d.p.)


Now reform the data first by tidy up the variable name of route into characters.
```{r}
NYC_transit_adpt = mutate(NYC_transit,across(route1:route11, as.character))
```

Then, first get the reform data so that route number and route name are distinct variables. 
```{r}
reform_NYC_transit = 
pivot_longer(NYC_transit_adpt,
    route1:route11,
    names_to = "route_number", 
    values_to = "route_name",
    values_drop_na = TRUE)
reform_NYC_transit
```

To answer the question of How many distinct stations serve the A train, I need to first filter the stations that serve A train and then return all the distinct stations by distinct function. Lastly, get the number by nrow(). Also I print out all the combinations in distinct_station_A dataframe.

```{r}
distinct_station_A = filter(reform_NYC_transit,route_name=='A') %>%
  distinct( line,station_name,.keep_all=TRUE) 

print(nrow(distinct_station_A))

distinct_station_A
```
There are 60 distinct stations serve the A train.  

```{r}
ADA_distinct_station_A = filter(distinct_station_A,ada=='TRUE')
ADA_distinct_station_A
print(nrow(ADA_distinct_station_A))
```
By filtering all ada compliant from the distinct stations serve the A train and return the number by using nrow, there are 17 station are ADA compliant. All stored in ADA_distinct_station_A dataframe



# Problem 2
First, load the data. The first line of the data is a logo, in which need to skip it. Also exclude the last several columns by specifying the columns that need to be included in the range argument in read_excel. After clean the names, change the variable name of weight_tons to weight and Volume_cubic_yards to volume. After that, ommit rows that does not include dumpster-specific data using drop_na function. Lastly, round the number of sports balls to the nearest integer and converts the result to an integer variable.
```{r}
Mr_trash_wheel = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",skip = 1,sheet=1,range = cellranger::cell_cols("A:N"))  %>%
  janitor::clean_names() %>%
  select(dumpster=dumpster, weight = weight_tons,volume = volume_cubic_yards,everything())%>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(sports_balls))
  
Mr_trash_wheel
```


Now do the similar process to Professor Trash Wheel. There is no sports balls in the dataset so do not need to consider as.integer(sports_balls).

```{r}
Prof_trash_wheel = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",skip = 1,sheet=2,range = cellranger::cell_cols("A:M"))  %>%
  janitor::clean_names() %>%
  select(dumpster=dumpster, weight = weight_tons,volume = volume_cubic_yards,everything())%>%
  drop_na(dumpster)
  
Prof_trash_wheel
```

In the new dataset, there is no sportsball. Hence need to create a column named as sportsball. Then, add a column specifying the dataset is Mr or Prof before joining two dataframes vertically using rbind:

```{r}
Prof_trash_wheel$sports_balls=NA
Mr_trash_wheel = mutate(Mr_trash_wheel, Mr_or_prof = 'Mr')
Prof_trash_wheel = mutate(Prof_trash_wheel, Mr_or_prof = 'Prof')
merged_df = rbind(Mr_trash_wheel,Prof_trash_wheel)
```

The data has a total of ```r nrow(merged_df)``` number of time that trash is collected and dumped into a dumpster after combining Mr_trash_wheel and Prof_trash_wheel. Out of all dataset, Mr. trash wheel contains ```r nrow(Mr_trash_wheel)``` number of data and Professor trash wheel contains ```r nrow(Prof_trash_wheel)``` number of data. 

The key variables are the weight of dumpster measuring in tons and the total of all dumpsters weight ```r sum(merged_df$weight)``` tons. For the data collected by Mr Trash wheel, the total weight is ```r sum(filter(merged_df,Mr_or_prof=='Mr')$weight)``` tons whereas Prof Trash wheel has a sum of ```r sum(filter(merged_df,Mr_or_prof=='Prof')$weight)``` tons. Another important factor is the volume of dumpsters, measuring in cubic yards. The total volume of all dumpsters is  ```r sum(merged_df$volume)``` cubic yards. For the data collected by Mr Trash wheel, the total volume is ```r sum(filter(merged_df,Mr_or_prof=='Mr')$volume)``` cubic yards whereas Prof Trash wheel has a total of ```r sum(filter(merged_df,Mr_or_prof=='Prof')$volume)``` cubic yards. 

The dataset also measures number of plastic bottles, cigarette butts, glass bottles, grocery bags and chip bags collected in dumpster. The total number of the above variables is: ```r sum(merged_df$plastic_bottles)```, ```r sum(merged_df$cigarette_butts)```, ```r sum(merged_df$glass_bottles)```, ```r sum(merged_df$grocery_bags)```, ```r sum(merged_df$chip_bags)``` respectively. The number of sports ball, however, is only contained in Mr. Trash Wheel dataset, and there are a total number of  ```r sum(filter(merged_df,Mr_or_prof=='Mr', year == 2020)$sports_balls)``` number of sports balls collected by Mr. Trash Wheel. 



The total weight of trash collected by Professor Trash Wheel is ```r sum(filter(merged_df,Mr_or_prof=='Prof')$weight)``` tons. 
The total number of sports balls collected by Mr. Trash Wheel in 2020 is ```r sum(filter(merged_df,Mr_or_prof=='Mr', year == 2020)$sports_balls)```



# Problem 3
1. Read the dataset 
2. Clean the names. 
3. Separate the mon variable into variables year month and day.
4. As instructed, these variables need to be in integers. Therefore, use mutate function to convert all values in the variables into integers.
5. After that, convert month into month name using moth.abb function in r. 
6. Then, create a president variable containing a classification of 'dem' or 'goz'. If prez_dem==1, the president is democratic, otherwise the president is republican  and must have prez_dem==1. Therefore, I can use ifelse function to check if presidence is gop or dem.  
7. Follows the last step, I remove the columns of prez_dem and prez_gop using select function. 
8. Also remove the day variable in the last step.

```{r}
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(mon,c('year','month','day'),sep='-') %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  mutate(month = month.abb[month]) %>%
  mutate(president = ifelse(prez_dem==1,'dem','gop')) %>%
  select(-prez_dem,-prez_gop) %>%
  select(-day)
pols_month
```

Now move on to cleaning the data in snp.csv with similar procedure:
1. Read the data
2. Clean variable name
3. Seperate date into month day year
4. Get into integer values
5. If year is smaller than 22, it means year is from 2000 to 2022, thus, add 2000 to the year value. If it is bigger than 22, i.e. 50, it means it is year 1950. Hence add 1900 if year is bigger than 22. Use ifelse function to do so
6. Get month into month name
7. Get rid of column of day
8. Organize so that year and month are leading columns

```{r}
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(date,c('month','day','year'),sep='/') %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  mutate(year = ifelse(year<22,year+2000,year+1900))%>%
  mutate(month = month.abb[month]) %>%
  select(-day)%>%
  select(year, month, everything())
head(snp)
```

For unemployment data:
The unemployment data has months in seperate columns with respect to years. It needs to be convert into long format:
1. load the data
2. All the data name are in desired form but need to convert Year to lower case year
3. Convert into long format
```{r}
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv",show_col_types = FALSE) %>%
  select(year = Year, everything())%>%
  pivot_longer(Jan:Dec,names_to = "month", values_to = "unemployment")
```

Now join the snp into pols. The reason for using left_join is that pols has the longest time period and start from 1947. I want to include all the existing information. If I want to do data analysis using datas that have full values (i.e. no missing values), I can use a period from 1947 to 2015. If I want to conduct data analysis on data that has missing value, I can discard them later using omit.na(). This make sure the data analysis contains as much information as possible. Thus, I use left_joint. So now pols are the dataframe that need to contain all the values. Then join unemployment into pols_snp, so pols_snp contains all the values. 

```{r}
pols_snp = left_join(pols_month,snp,by = c("year", "month"))
pols_snp_unemployment = left_join(pols_snp,unemployment,by = c("year", "month"))
pols_snp_unemployment
```

Dataset pols_month contains all the information related to whether president was republican or democratic. It also contains the number of governors, senators and representatives in each party. The total dimension is ```r nrow(pols_month)``` with ```r ncol(pols_month)``` variables after tidying data. The range of year is from ```r min(pols_month$year)``` to ```r max(pols_month$year)```.  

snp, on the other hand, contains the closing values of stock market index on the association date. The total dimension for snp is ```r nrow(snp)``` and there are only ```r ncol(snp)``` variables after tidying data, including year and month. The values of stock market index ranging from year ```r min(snp$year)``` to ```r max(snp$year)```.  

Unemployment contains the unemployment rate with respect to different months in different years, ranging from year ```r min(unemployment$year)``` to ```r max(unemployment$year)```. There are ```r nrow(unemployment)``` number of data and ```r ncol(unemployment)``` of variables including year and month.

Now the merged dataset includes all three datasets, namely pols_month, snp and unemployment. The resulting data has the same dimension as pols_month data but with a wider range of variables. It has a total of ```r ncol(pols_snp_unemployment)``` variables, namely year and month as the key and 6 measurement of number of governors, senators and representatives with respect to each party, 1 variable of president measuring whether the president from democrative or republican, closing values of stock market index and unemployment. Although with some missing value, the year is from ```r min(pols_snp_unemployment$year)``` to ```r max(pols_snp_unemployment$year)```.


